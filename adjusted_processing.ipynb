{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collection of helper function iterated off of a previous Groups work. Change have been for clarity and preformance optimization \n",
    "def convert_to_datetime(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str + '-01', format='%Y-%m-%d')  # Assume first day of the month if YYYY-MM format\n",
    "        except ValueError:\n",
    "            return pd.NaT  # Return NaT (Not a Time) if conversion fails\n",
    "        \n",
    "def count_loc(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    else:\n",
    "        new_string = value.split(\", \")\n",
    "        counter = sum(1 for i in new_string if \"facility\" in i)\n",
    "        return counter\n",
    "    \n",
    "def trial_loc(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    else:\n",
    "        new_string = value.split(\", \")\n",
    "        temp_list = [i for i in new_string if \"country\" in i]\n",
    "        has_us = any(\"United States\" in i for i in temp_list)\n",
    "\n",
    "        if all(i == temp_list[0] for i in temp_list) and has_us:\n",
    "            loc = 'USA'\n",
    "        elif not has_us:\n",
    "            loc = \"non-USA\"\n",
    "        else:\n",
    "            loc = \"USA & non-USA\"\n",
    "        return loc\n",
    "    \n",
    "def extract_measures(outcomes):\n",
    "    if isinstance(outcomes, list):\n",
    "        return [item.get('measure', 'No description available') for item in outcomes]\n",
    "    else:\n",
    "        return ['No description available']  # Return a list with a default message if not iterable\n",
    "\n",
    "\n",
    "def extract_timeframes(outcomes):\n",
    "    if isinstance(outcomes, list):\n",
    "        return [item.get('timeFrame', 'No description available') for item in outcomes]\n",
    "    else:\n",
    "        return ['No description available']  # Return a list with a default message if not iterable\n",
    "\n",
    "def extract_time_length_from_list(timeFrames):\n",
    "    written_numbers = {\n",
    "        \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \n",
    "        \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9, \"ten\": 10,\n",
    "        \"eleven\": 11, \"twelve\": 12, \"thirteen\": 13, \"fourteen\": 14,\n",
    "        \"fifteen\": 15, \"sixteen\": 16, \"seventeen\": 17, \"eighteen\": 18,\n",
    "        \"nineteen\": 19, \"twenty\": 20\n",
    "    }\n",
    "\n",
    "\n",
    "    number_pattern = r\"(\\d+(\\.\\d+)?)\"\n",
    "    written_number_pattern = r\"(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty)\"\n",
    "    unit_pattern = r\"(hour|day|week|month|year|minute)s?\"\n",
    "    reversed_pattern = rf\"(?P<unit3>{unit_pattern})\\s+(?P<number2>\\d+(\\.\\d+)?)\"\n",
    "\n",
    "    time_pattern = re.compile(\n",
    "        rf\"\"\"\n",
    "        (?:\n",
    "            (?P<number>{number_pattern})\\s*(?P<unit1>{unit_pattern}) |\n",
    "            (?P<written>{written_number_pattern})\\s*(?P<unit2>{unit_pattern}) |\n",
    "            {reversed_pattern}\n",
    "        )\n",
    "        \"\"\",\n",
    "        re.IGNORECASE | re.VERBOSE\n",
    "    )\n",
    "\n",
    "    def extract_time_length(timeFrame):\n",
    "        results = time_pattern.findall(timeFrame)\n",
    "        time_durations = []\n",
    "\n",
    "        for result in results:\n",
    "            if result[0]:\n",
    "                number, unit = result[0], result[3]\n",
    "            elif result[5]:\n",
    "                number, unit = written_numbers[result[5].lower()], result[7]\n",
    "            elif result[10]:\n",
    "                number, unit = result[11], result[9]\n",
    "\n",
    "            number = float(number) if isinstance(number, str) else number\n",
    "            time_durations.append((number, unit.lower()))\n",
    "        return time_durations\n",
    "\n",
    "    return [\n",
    "        duration\n",
    "        for timeFrame in timeFrames if timeFrame\n",
    "        for duration in extract_time_length(timeFrame)\n",
    "    ]\n",
    "\n",
    "def convert_to_days(amount, unit):\n",
    "    if unit in ['minutes', 'minute']:\n",
    "        return np.ceil(amount / 1440)\n",
    "    elif unit in ['hours', 'hour']:\n",
    "        return np.ceil(amount / 24)\n",
    "    elif unit in ['weeks', 'week']:\n",
    "        return amount * 7\n",
    "    elif unit in ['months', 'month']:\n",
    "        return amount * 30  \n",
    "    elif unit in ['years', 'year']:\n",
    "        return amount * 365 \n",
    "    elif unit in ['days', 'day']:\n",
    "        return amount\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def find_max_duration(durations):\n",
    "    if not durations:  # Check if the list is empty\n",
    "        return np.nan  \n",
    "    max_days = max(convert_to_days(amount, unit) for amount, unit in durations)\n",
    "    return max_days\n",
    "\n",
    "def remove_special_chars(col):\n",
    "    # Define a translation table to replace characters with underscores\n",
    "    translation_table = str.maketrans({ord(char): '_' for char in \"[]',\"})\n",
    "    \n",
    "    # Use translate method to apply the translation table\n",
    "    cleaned_col = col.translate(translation_table)\n",
    "    \n",
    "    return cleaned_col\n",
    "\n",
    "def count_criteria(criteria):\n",
    "    if pd.isna(criteria):\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    pattern = r'\\n\\s*\\w{1,2}\\.|[*]|\\-'  # Pattern to match alphanumeric followed by period, asterisk, or hyphen\n",
    "    \n",
    "    if \"exclusion criteria\" in criteria.lower():\n",
    "        parts = criteria.lower().split(\"exclusion criteria\", 1)  # Split only once to preserve the rest\n",
    "        inclusion_criteria = parts[0]\n",
    "        exclusion_criteria = parts[1]\n",
    "\n",
    "        inclusion_matches = re.findall(pattern, inclusion_criteria)\n",
    "        exclusion_matches = re.findall(pattern, exclusion_criteria)\n",
    "        num_inclusion = len(inclusion_matches)\n",
    "        num_exclusion = len(exclusion_matches)\n",
    "    else:\n",
    "        inclusion_matches = re.findall(pattern, criteria)\n",
    "        num_inclusion = len(inclusion_matches)\n",
    "        num_exclusion = np.nan\n",
    "    \n",
    "    return num_inclusion, num_exclusion\n",
    "\n",
    "def conditions_map(condition):\n",
    "    condition = condition.lower() \n",
    "    \n",
    "    category_map = {\n",
    "        'squamous cell': ['cell lung', 'head and neck', 'squamous cell', 'small cell', 'lung', 'keratosis', 'nsclc'],\n",
    "        'myeloma': ['myeloma'],\n",
    "        'sarcoma': ['sarcoma'],\n",
    "        'lymphoma': ['lymphoma', 'lymphoid'],\n",
    "        'brain': ['brain cancer', 'glioblastoma'],\n",
    "        'melanoma': ['melanoma'],\n",
    "        'adeno': ['adenocarcinoma', 'prostate cancer', 'colorectal', 'kidney', 'renal', 'cervix', 'cervical', 'liver', 'hepatic', 'hepatocellular', 'thyroid'],\n",
    "        'ductal': ['breast'],\n",
    "        'leukemia': ['leukemia', 'hematopoietic'],\n",
    "        'pain': ['pain'],\n",
    "        'carcinoma': ['carcinoma']\n",
    "    }\n",
    "    \n",
    "    for category, keywords in category_map.items():\n",
    "        if any(keyword in condition for keyword in keywords):\n",
    "            return category\n",
    "    \n",
    "    return 'other'\n",
    "\n",
    "def list_to_lower_string(lst):\n",
    "    # Check if input is iterable (not strictly requiring a list)\n",
    "    if hasattr(lst, '__iter__'):\n",
    "        # Convert each element to lowercase string and join with \", \"\n",
    "        return \", \".join(map(str, lst)).lower()\n",
    "    else:\n",
    "        return \"\"  # Return empty string if input is not iterable\n",
    "\n",
    "\n",
    "\n",
    "def drop_outliers(df, threshold=5):\n",
    "    # Calculate z-scores for each column\n",
    "    z_scores = np.abs((df - df.mean()) / df.std())\n",
    "    \n",
    "    # Identify outliers using the threshold\n",
    "    outlier_mask = z_scores > threshold\n",
    "    \n",
    "    # Drop rows containing any outliers\n",
    "    df_cleaned = df[~outlier_mask.any(axis=1)]\n",
    "    \n",
    "    return df_cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start data processing\n",
    "df = pd.read_csv(r'C:\\Users\\Spenc\\OneDrive\\Documents\\Masters Thesis\\ctg-studies.csv')\n",
    "# len of rows\n",
    "rows0 = len(df)\n",
    "\n",
    "def process_study_duration(df):\n",
    "    # Convert dates to datetime\n",
    "    df['start_date'] = df['protocolSection_statusModule_startDateStruct_date'].apply(convert_to_datetime)\n",
    "    df['primary_completion_date'] = df['protocolSection_statusModule_primaryCompletionDateStruct_date'].apply(convert_to_datetime)\n",
    "    df['completion_date'] = df['protocolSection_statusModule_completionDateStruct_date'].apply(convert_to_datetime)\n",
    "    \n",
    "    # Calculate study durations in days\n",
    "    df['primary_study_duration_days'] = (df['primary_completion_date'] - df['start_date']).dt.days\n",
    "    df['study_duration_days'] = (df['completion_date'] - df['start_date']).dt.days\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_and_report_missing(df):\n",
    "    # Define columns that are vital for accurate prediction\n",
    "    need_cols = [\n",
    "        'primary_study_duration_days',\n",
    "        'study_duration_days',\n",
    "        'protocolSection_designModule_enrollmentInfo_count']\n",
    "\n",
    "    # Calculate initial number of rows\n",
    "    initial_rows = len(df)\n",
    "    # Drop rows with NaNs in vital columns and create a copy of the DataFrame\n",
    "    df_cleaned = df.dropna(subset=need_cols).copy()\n",
    "    # Calculate number of rows after dropping NaNs\n",
    "    cleaned_rows = len(df_cleaned)\n",
    "    # Calculate the number of rows dropped\n",
    "    dropped_rows = initial_rows - cleaned_rows\n",
    "    # Print message about dropped rows\n",
    "    print(f\"{dropped_rows} rows were dropped due to missing values in one of: {need_cols}\")\n",
    "\n",
    "    return df_cleaned, dropped_rows\n",
    "\n",
    "def create_bins_and_count_criteria(df, n_intervals=5):\n",
    "    # Create bins for study duration and primary study duration\n",
    "    df['study_eq_bins'] = pd.qcut(df['study_duration_days'], q=n_intervals, labels=False)\n",
    "    df['primary_eq_bins'] = pd.qcut(df['primary_study_duration_days'], q=n_intervals, labels=False)\n",
    "\n",
    "    # Calculate bin labels for study and primary study durations\n",
    "    df['study_eq_labels'] = pd.qcut(df['study_duration_days'], q=n_intervals, labels=False)\n",
    "    df['primary_eq_labels'] = pd.qcut(df['primary_study_duration_days'], q=n_intervals, labels=False)\n",
    "\n",
    "    # Create a dictionary of bin labels and corresponding intervals for study duration\n",
    "    bins_dict = df.groupby('study_eq_labels')['study_eq_bins'].first().to_dict()\n",
    "    msg = f\"Bin labels and their corresponding intervals for study duration are: {bins_dict}\"\n",
    "    print(msg)\n",
    "\n",
    "    # Extract number of inclusion and exclusion criteria\n",
    "    df[['num_inclusion', 'num_exclusion']] = df['protocolSection_eligibilityModule_eligibilityCriteria'].apply(count_criteria).apply(pd.Series)\n",
    "\n",
    "    return df\n",
    "\n",
    "def map_sponsor_type(df):\n",
    "    # Define mappings for sponsor types\n",
    "    sponsor_class_map = {\n",
    "        'OTHER_GOV': 'OTHER',\n",
    "        'NETWORK': 'OTHER',\n",
    "        'NIH': 'OTHER',\n",
    "        'FED': 'OTHER',\n",
    "        'INDIV': 'OTHER'\n",
    "    }\n",
    "\n",
    "    sponsor_type_map = {\n",
    "        \"INDUSTRY\": 1,\n",
    "        \"OTHER\": 0\n",
    "    }\n",
    "\n",
    "    # Apply mapping for sponsor class\n",
    "    df['sponsor_type_class'] = df['protocolSection_sponsorCollaboratorsModule_leadSponsor_class'].replace(sponsor_class_map)\n",
    "\n",
    "    # Map sponsor type based on mapped sponsor class\n",
    "    df['sponsor_type'] = df['sponsor_type_class'].map(sponsor_type_map)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_conditions_and_model(df):\n",
    "    # Number of conditions, integer\n",
    "    df['protocolSection_conditionsModule_conditions'] = df['protocolSection_conditionsModule_conditions'].apply(ast.literal_eval)\n",
    "    df['number_of_conditions'] = df['protocolSection_conditionsModule_conditions'].apply(lambda x: len(x))\n",
    "\n",
    "    # Intervention model, categorical (mapped to int/float)\n",
    "    intervention_model_map = {\n",
    "        \"CROSSOVER\": \"OTHER\",\n",
    "        \"SEQUENTIAL\": \"OTHER\",\n",
    "        \"FACTORIAL\": \"OTHER\"\n",
    "    }\n",
    "\n",
    "    intervention_model_map2 = {\n",
    "        \"SINGLE_GROUP\": 0,\n",
    "        \"PARALLEL\": 1,\n",
    "        \"OTHER\": 2\n",
    "    }\n",
    "\n",
    "    # Apply mappings for intervention model\n",
    "    df['intervention_model_mapped'] = df['protocolSection_designModule_designInfo_interventionModel'].replace(intervention_model_map)\n",
    "    df['intervention_model'] = df['intervention_model_mapped'].map(intervention_model_map2)\n",
    "\n",
    "    # Drop intermediate column\n",
    "    df.drop(columns=['intervention_model_mapped'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_study_design(df):\n",
    "    # Primary purpose, bool/int\n",
    "    df['protocolSection_designModule_designInfo_primaryPurpose'] = df['protocolSection_designModule_designInfo_primaryPurpose'].fillna('')\n",
    "    df['treatment_purpose'] = df['protocolSection_designModule_designInfo_primaryPurpose'].apply(lambda x: 1 if 'TREATMENT' in x else 0)\n",
    "    df['diagnostic_purpose'] = df['protocolSection_designModule_designInfo_primaryPurpose'].apply(lambda x: 1 if 'DIAGNOSTIC' in x else 0)\n",
    "    df['prevention_purpose'] = df['protocolSection_designModule_designInfo_primaryPurpose'].apply(lambda x: 1 if 'PREVENTION' in x else 0)\n",
    "    df['supportive_purpose'] = df['protocolSection_designModule_designInfo_primaryPurpose'].apply(lambda x: 1 if 'SUPPORTIVE_CARE' in x else 0)\n",
    "\n",
    "    # Intervention type, bool/int\n",
    "    df['protocolSection_armsInterventionsModule_interventions'] = df['protocolSection_armsInterventionsModule_interventions'].apply(ast.literal_eval)\n",
    "    df['procedure_intervention'] = df['protocolSection_armsInterventionsModule_interventions'].apply(lambda x: 1 if 'PROCEDURE' in x else 0)\n",
    "    df['device_intervention'] = df['protocolSection_armsInterventionsModule_interventions'].apply(lambda x: 1 if 'DEVICE' in x else 0)\n",
    "    df['behavioral_intervention'] = df['protocolSection_armsInterventionsModule_interventions'].apply(lambda x: 1 if 'BEHAVIORAL' in x else 0)\n",
    "    df['drug_intervention'] = df['protocolSection_armsInterventionsModule_interventions'].apply(lambda x: 1 if 'DRUG' in x else 0)\n",
    "    df['radiation_intervention'] = df['protocolSection_armsInterventionsModule_interventions'].apply(lambda x: 1 if 'RADIATION' in x else 0)\n",
    "    df['biological_intervention'] = df['protocolSection_armsInterventionsModule_interventions'].apply(lambda x: 1 if 'BIOLOGICAL' in x else 0)\n",
    "\n",
    "    # Number of groups, int\n",
    "    df['number_of_groups'] = df['protocolSection_armsInterventionsModule_armGroups'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "    # Number of intervention types, int\n",
    "    df['number_of_intervention_types'] = df['intervention_types'].apply(len)\n",
    "\n",
    "    return df\n",
    "\n",
    "def map_age_groups(df):\n",
    "    # Age group, categorical (mapped to int/float)\n",
    "    age_map = {\n",
    "        \"['ADULT', 'OLDER_ADULT']\": \"adult\",\n",
    "        \"['ADULT']\": \"adult\",\n",
    "        \"['OLDER_ADULT']\": \"adult\",\n",
    "        \"['CHILD']\": \"youth\",\n",
    "        \"['CHILD', 'ADULT']\": \"youth\",\n",
    "        \"['CHILD', 'ADULT', 'OLDER_ADULT']\": \"all\"\n",
    "    }\n",
    "\n",
    "    age_map2 = {\n",
    "        \"youth\": 0,\n",
    "        \"adult\": 1,\n",
    "        \"all\": 2\n",
    "    }\n",
    "\n",
    "    df[\"age_group0\"] = df[\"protocolSection_eligibilityModule_stdAges\"].map(age_map)\n",
    "    df[\"age_group\"] = df[\"age_group0\"].map(age_map2)\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_location_data(df):\n",
    "    # Number of locations, int\n",
    "    df[\"num_locations\"] = df[\"protocolSection_contactsLocationsModule_locations\"].apply(count_loc)\n",
    "\n",
    "    # Location of trials, categorical\n",
    "    loc_map = {\n",
    "        \"USA\": 0,\n",
    "        \"non-USA\": 1,\n",
    "        \"USA & non-USA\": 2\n",
    "    }\n",
    "\n",
    "    df['location0'] = df[\"protocolSection_contactsLocationsModule_locations\"].apply(trial_loc)\n",
    "    df['location'] = df['location0'].map(loc_map)\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_outcome_measures(df):\n",
    "    # Combine outcome measures\n",
    "    df['outcome_measures'] = df['protocolSection_outcomesModule_primaryOutcomes'] + df['protocolSection_outcomesModule_secondaryOutcomes']\n",
    "    df['outcome_measures'] = df['outcome_measures'].astype('str').str.lower()\n",
    "\n",
    "    # OS outcome measure\n",
    "    df['os_outcome_measure'] = df['outcome_measures'].apply(lambda x: 1 if ' os ' in x or 'overall survival' in x else 0)\n",
    "\n",
    "    # Adverse event outcome measure\n",
    "    df['ae_outcome_measure'] = df['outcome_measures'].apply(lambda x: 1 if 'adverse event' in x else 0)\n",
    "\n",
    "    # DOR outcome measure\n",
    "    df['dor_outcome_measure'] = df['outcome_measures'].apply(lambda x: 1 if ' dor ' in x or 'duration of response' in x else 0)\n",
    "\n",
    "    # Max timeframe from primary outcome measures\n",
    "    df['primary_measure'] = df['protocolSection_outcomesModule_primaryOutcomes'].apply(extract_measures)\n",
    "    df['primary_timeFrame'] = df['protocolSection_outcomesModule_primaryOutcomes'].apply(extract_timeframes)\n",
    "    df['primary_duration'] = df['primary_timeFrame'].apply(extract_time_length_from_list)\n",
    "    df['primary_max_days'] = df['primary_duration'].apply(find_max_duration)\n",
    "\n",
    "    # Max timeframe from secondary outcome measures\n",
    "    df['secondary_measure'] = df['protocolSection_outcomesModule_secondaryOutcomes'].apply(extract_measures)\n",
    "    df['secondary_timeFrame'] = df['protocolSection_outcomesModule_secondaryOutcomes'].apply(extract_timeframes)\n",
    "    df['secondary_duration'] = df['secondary_timeFrame'].apply(extract_time_length_from_list)\n",
    "    df['secondary_max_days'] = df['secondary_duration'].apply(find_max_duration)\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df = df.drop(columns=['os_outcome_measure2', 'dor_outcome_measure2'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_oversight_and_responsible_party(df):\n",
    "    # Convert to lowercase and map 'true'/'false' to 1/0 for has_dmc\n",
    "    df['protocolSection_oversightModule_oversightHasDmc'] = df['protocolSection_oversightModule_oversightHasDmc'].astype(str).str.lower()\n",
    "    dmc_map = {'true': 1, 'false': 0}\n",
    "    df['has_dmc'] = df['protocolSection_oversightModule_oversightHasDmc'].map(dmc_map)\n",
    "\n",
    "    # Map responsible party types to integers\n",
    "    party_map = {\n",
    "        \"PRINCIPAL_INVESTIGATOR\": 0,\n",
    "        \"SPONSOR\": 1,\n",
    "        \"SPONSOR_INVESTIGATOR\": 2\n",
    "    }\n",
    "    df['resp_party'] = df['protocolSection_sponsorCollaboratorsModule_responsibleParty_type'].map(party_map)\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_design_and_conditions(df):\n",
    "    # Allocation mapping\n",
    "    allo_map = {\n",
    "        'NON_RANDOMIZED': 0,\n",
    "        'RANDOMIZED': 1\n",
    "    }\n",
    "    df['allocation'] = df['protocolSection_designModule_designInfo_allocation'].map(allo_map)\n",
    "\n",
    "    # Masking mapping\n",
    "    mask_map = {\n",
    "        \"NONE\": 0,\n",
    "        \"SINGLE\": 1,\n",
    "        \"DOUBLE\": 2,\n",
    "        \"TRIPLE\": 3,\n",
    "        \"QUADRUPLE\": 4\n",
    "    }\n",
    "    df['masking'] = df['protocolSection_designModule_designInfo_maskingInfo_masking'].map(mask_map)\n",
    "\n",
    "    # Convert conditions to lowercase string and map to categories\n",
    "    df['conditions'] = df['protocolSection_conditionsModule_conditions'].apply(list_to_lower_string)\n",
    "    df['conditions_category'] = df['conditions'].apply(lambda x: conditions_map(x))\n",
    "\n",
    "    # Category mapping dictionary\n",
    "    category_map = {\n",
    "        'myeloma': 0, 'squamous cell': 1, 'adeno': 2, 'carcinoma': 3, \n",
    "        'leukemia': 4, 'ductal': 5, 'sarcoma': 6, 'lymphoma': 7, \n",
    "        'melanoma': 8, 'brain': 9, 'pain': 10, 'other': 11\n",
    "    }\n",
    "    df['conditions_category_num'] = df['conditions_category'].map(category_map)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Consolidated mappings into a single dictionary\n",
    "conditions_map = {\n",
    "    'myeloma': {\n",
    "        'survival_5yr_relative': 0.598,\n",
    "        'max_treatment_duration': 180,\n",
    "        'min_treatment_duration': 90\n",
    "    },\n",
    "    'squamous cell': {\n",
    "        'survival_5yr_relative': 0.99,\n",
    "        'max_treatment_duration': 49,\n",
    "        'min_treatment_duration': 14\n",
    "    },\n",
    "    'adeno': {\n",
    "        'survival_5yr_relative': 0.175,\n",
    "        'max_treatment_duration': 1080,\n",
    "        'min_treatment_duration': 360\n",
    "    },\n",
    "    'carcinoma': {\n",
    "        'survival_5yr_relative': 0.99,\n",
    "        'max_treatment_duration': 1440,\n",
    "        'min_treatment_duration': 360\n",
    "    },\n",
    "    'leukemia': {\n",
    "        'survival_5yr_relative': 0.65,\n",
    "        'max_treatment_duration': 1095,\n",
    "        'min_treatment_duration': 730\n",
    "    },\n",
    "    'ductal': {\n",
    "        'survival_5yr_relative': 0.99,\n",
    "        'max_treatment_duration': 1825,\n",
    "        'min_treatment_duration': 365\n",
    "    },\n",
    "    'sarcoma': {\n",
    "        'survival_5yr_relative': 0.65,\n",
    "        'max_treatment_duration': 1825,\n",
    "        'min_treatment_duration': 240\n",
    "    },\n",
    "    'lymphoma': {\n",
    "        'survival_5yr_relative': 0.83,\n",
    "        'max_treatment_duration': 730,\n",
    "        'min_treatment_duration': 180\n",
    "    },\n",
    "    'melanoma': {\n",
    "        'survival_5yr_relative': 0.94,\n",
    "        'max_treatment_duration': 730,\n",
    "        'min_treatment_duration': 150\n",
    "    },\n",
    "    'brain': {\n",
    "        'survival_5yr_relative': 0.326,\n",
    "        'max_treatment_duration': 4320,\n",
    "        'min_treatment_duration': 1080\n",
    "    },\n",
    "    'pain': {\n",
    "        'survival_5yr_relative': 0.68,\n",
    "        'max_treatment_duration': 4320,\n",
    "        'min_treatment_duration': 14\n",
    "    },\n",
    "    'other': {\n",
    "        'survival_5yr_relative': 0.68,\n",
    "        'max_treatment_duration': 4320,\n",
    "        'min_treatment_duration': 14\n",
    "    }\n",
    "}\n",
    "\n",
    "def apply_conditions_mapping(df, conditions_column, conditions_map):\n",
    "    # Apply mappings to create new columns\n",
    "    df['conditions_category_info'] = df[conditions_column].map(conditions_map)\n",
    "    df = pd.concat([df, df['conditions_category_info'].apply(pd.Series)], axis=1)\n",
    "    df.drop(columns=['conditions_category_info'], inplace=True)  # Drop the intermediate column\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_and_save_data(df):\n",
    "    def drop_outliers(df, threshold=5):\n",
    "        # Calculate the mean and standard deviation for each column\n",
    "        means = df.mean()\n",
    "        stds = df.std()\n",
    "        # Identify outliers\n",
    "        outliers = (np.abs((df - means) / stds) > threshold)\n",
    "        # Create a DataFrame to store the outliers\n",
    "        dropped_values = df[outliers]\n",
    "        # Drop the rows with outliers\n",
    "        df_cleaned = df.drop(index=dropped_values.dropna(how='all').index)\n",
    "        return df_cleaned\n",
    "\n",
    "    def fill_missing_with_mode(df, columns):\n",
    "        for column in columns:\n",
    "            mode_value = df[column].mode()[0]  # Calculate the mode\n",
    "            df[column] = df[column].fillna(mode_value)\n",
    "        return df\n",
    "\n",
    "    def remove_special_chars(col_name):\n",
    "        # Replace special characters with underscores\n",
    "        return col_name.replace(' ', '_').replace('/', '_').replace('-', '_')\n",
    "\n",
    "    # Rename columns of interest\n",
    "    df = df.rename(columns={\n",
    "        'protocolSection_designModule_phases': 'phase',\n",
    "        'protocolSection_designModule_enrollmentInfo_count': 'enroll_count',\n",
    "        'protocolSection_eligibilityModule_healthyVolunteers': 'healthy_vol'\n",
    "    })\n",
    "\n",
    "    # Select columns of interest\n",
    "    cols = [\n",
    "        'protocolSection_identificationModule_nctId',\n",
    "        'primary_study_duration_days',\n",
    "        'study_duration_days',\n",
    "        'primary_eq_bins',\n",
    "        'study_eq_bins',\n",
    "        'study_eq_labels',\n",
    "        'primary_eq_labels',\n",
    "        'number_of_conditions',\n",
    "        'number_of_groups',\n",
    "        'age_group',\n",
    "        'num_locations',\n",
    "        'location',\n",
    "        'num_inclusion',\n",
    "        'num_exclusion',\n",
    "        'number_of_intervention_types',\n",
    "        'sponsor_type',\n",
    "        'intervention_model',\n",
    "        'resp_party',\n",
    "        'has_dmc',\n",
    "        'phase',\n",
    "        'allocation',\n",
    "        'masking',\n",
    "        'enroll_count',\n",
    "        'healthy_vol',\n",
    "        'treatment_purpose',\n",
    "        'diagnostic_purpose',\n",
    "        'prevention_purpose',\n",
    "        'supportive_purpose',\n",
    "        'procedure_intervention',\n",
    "        'device_intervention',\n",
    "        'behavioral_intervention',\n",
    "        'drug_intervention',\n",
    "        'radiation_intervention',\n",
    "        'biological_intervention',\n",
    "        'os_outcome_measure',\n",
    "        'dor_outcome_measure',\n",
    "        'ae_outcome_measure',\n",
    "        'primary_max_days',\n",
    "        'secondary_max_days',\n",
    "        'max_treatment_duration',\n",
    "        'min_treatment_duration',\n",
    "        'survival_5yr_relative',\n",
    "        'conditions_category_num'\n",
    "    ]\n",
    "\n",
    "    clean_df = df[cols].copy()\n",
    "\n",
    "    # Remove outliers\n",
    "    numeric_cols = clean_df.select_dtypes(include=['float16', 'float32', 'float64', 'int', 'int32', 'int64', 'bool']).columns\n",
    "    temp = clean_df[numeric_cols]\n",
    "    clean_temp = drop_outliers(temp)\n",
    "    clean_df = clean_df.loc[clean_temp.index]\n",
    "\n",
    "    # Print message about dropped outliers\n",
    "    msg_outliers = f\"The number of rows dropped due to outliers (greater than 5 standard deviations from the mean) is {len(df) - len(clean_df)}\"\n",
    "    print(msg_outliers)\n",
    "\n",
    "    # Handle missing values by filling with mode\n",
    "    nan_cols = clean_df.columns[clean_df.isna().any()].tolist()\n",
    "    nan_cols.remove('primary_max_days')\n",
    "    nan_cols.remove('secondary_max_days')\n",
    "    clean_df = fill_missing_with_mode(clean_df, nan_cols)\n",
    "\n",
    "    # One hot encode remaining object columns\n",
    "    object_columns = clean_df.select_dtypes(include=['object']).columns\n",
    "    object_columns = [col for col in object_columns if 'nctId' not in col]\n",
    "    encoded_df = pd.get_dummies(clean_df, columns=object_columns)\n",
    "\n",
    "    # Apply function to clean column names\n",
    "    encoded_df.columns = encoded_df.columns.map(remove_special_chars)\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    train_df, test_df = train_test_split(encoded_df, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "    output_dir = \"C:\\\\Users\\\\Spenc\\\\OneDrive\\\\Documents\\\\Masters Thesis\\\\\"\n",
    "\n",
    "\n",
    "\n",
    "    # Ensure the directory exists; create if it doesn't\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save the cleaned data to CSV files in the specified directory\n",
    "    train_df.to_csv(os.path.join(output_dir, \"cleaned_data_train.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(output_dir, \"cleaned_data_test.csv\"), index=False)\n",
    "\n",
    "process_study_duration(df)\n",
    "#clean_and_report_missing(df)\n",
    "\n",
    "#create_bins_and_count_criteria(df, n_intervals=5)\n",
    "\n",
    "data_msg = \"Data processing completed.\"\n",
    "print(data_msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
