{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n"
      ],
      "metadata": {
        "id": "M1h_a29ngraa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "110CyClPeutf"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"/content/max_days.xlsx\")\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "#split the two columns I want to tokenize\n",
        "primary_measure = df['primary_measure']\n",
        "\n",
        "secondary_measure = df['secondary_measure']\n"
      ]
    },
    {
      "source": [
        "\n",
        "# Download NLTK stopwords (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Get NLTK English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Process text with spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Lemmatize and remove punctuation and whitespace\n",
        "    tokens = [token.lemma_.lower() for token in doc if not token.is_punct and not token.is_space]\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    return tokens\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hig_XCuviI6g",
        "outputId": "ea1b710b-1be5-4690-ef80-5243e9e745e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocess_text function to primary_measure column\n",
        "primary_measure = primary_measure = df['primary_measure'].apply(preprocess_text)\n",
        "\n",
        "# Apply preprocess_text function to secondary_measure column\n",
        "secondary_measure = df['secondary_measure'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "lAuejnBJhME4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Combine preprocessed texts into a single list of strings\n",
        "preprocessed_texts = [' '.join(tokens) for tokens in primary_measure]\n",
        "# Initialize TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# TF-IDF vectorization\n",
        "X = vectorizer.fit_transform(preprocessed_texts)\n",
        "\n",
        "# Convert sparse matrix to DataFrame (optional for visualization)\n",
        "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display TF-IDF DataFrame\n",
        "print(tfidf_df)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h78Qg9fsk41G",
        "outputId": "080478f3-4e6a-48ab-a3e9-d5cd57f87438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       03   06  06dec2019  093   10       100  1007  100x10  101  106  ...  \\\n",
            "0     0.0  0.0        0.0  0.0  0.0  0.000000   0.0     0.0  0.0  0.0  ...   \n",
            "1     0.0  0.0        0.0  0.0  0.0  0.000000   0.0     0.0  0.0  0.0  ...   \n",
            "2     0.0  0.0        0.0  0.0  0.0  0.000000   0.0     0.0  0.0  0.0  ...   \n",
            "3     0.0  0.0        0.0  0.0  0.0  0.000000   0.0     0.0  0.0  0.0  ...   \n",
            "4     0.0  0.0        0.0  0.0  0.0  0.000000   0.0     0.0  0.0  0.0  ...   \n",
            "...   ...  ...        ...  ...  ...       ...   ...     ...  ...  ...  ...   \n",
            "1629  0.0  0.0        0.0  0.0  0.0  0.000000   0.0     0.0  0.0  0.0  ...   \n",
            "1630  0.0  0.0        0.0  0.0  0.0  0.324641   0.0     0.0  0.0  0.0  ...   \n",
            "1631  0.0  0.0        0.0  0.0  0.0  0.000000   0.0     0.0  0.0  0.0  ...   \n",
            "1632  0.0  0.0        0.0  0.0  0.0  0.000000   0.0     0.0  0.0  0.0  ...   \n",
            "1633  0.0  0.0        0.0  0.0  0.0  0.000000   0.0     0.0  0.0  0.0  ...   \n",
            "\n",
            "      york      ypn0      ypt0  ypt0n0   yr  zinc  zoladex  zone  zoster   Âµg  \n",
            "0      0.0  0.000000  0.000000     0.0  0.0   0.0      0.0   0.0     0.0  0.0  \n",
            "1      0.0  0.209101  0.209101     0.0  0.0   0.0      0.0   0.0     0.0  0.0  \n",
            "2      0.0  0.000000  0.000000     0.0  0.0   0.0      0.0   0.0     0.0  0.0  \n",
            "3      0.0  0.000000  0.000000     0.0  0.0   0.0      0.0   0.0     0.0  0.0  \n",
            "4      0.0  0.000000  0.000000     0.0  0.0   0.0      0.0   0.0     0.0  0.0  \n",
            "...    ...       ...       ...     ...  ...   ...      ...   ...     ...  ...  \n",
            "1629   0.0  0.000000  0.000000     0.0  0.0   0.0      0.0   0.0     0.0  0.0  \n",
            "1630   0.0  0.000000  0.000000     0.0  0.0   0.0      0.0   0.0     0.0  0.0  \n",
            "1631   0.0  0.000000  0.000000     0.0  0.0   0.0      0.0   0.0     0.0  0.0  \n",
            "1632   0.0  0.000000  0.000000     0.0  0.0   0.0      0.0   0.0     0.0  0.0  \n",
            "1633   0.0  0.000000  0.000000     0.0  0.0   0.0      0.0   0.0     0.0  0.0  \n",
            "\n",
            "[1634 rows x 2649 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['study_duration_days'].values\n",
        "\n",
        "# Initialize imputer to replace NaNs with the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Fit the imputer on your data and transform 'y' to replace NaNs\n",
        "y_imputed = imputer.fit_transform(y.reshape(-1, 1)).ravel()  # Reshape for single feature\n"
      ],
      "metadata": {
        "id": "iNdvCL_FmJSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_imputed, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "-HQuFgnDnXAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "#Base\n",
        "# Initialize the regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R-squared:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qlb3bkNln6yN",
        "outputId": "3681eb33-e7f1-49ff-ad88-3b8acd810884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 1641143.5851114725\n",
            "R-squared: -1.2828049421680885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#idea one, just trying stuff\n",
        "# Example of trying Ridge Regression with hyperparameter tuning\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Initialize Ridge Regression model\n",
        "ridge_model = Ridge()\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {'alpha': [0.1, 1.0, 10.0]}  # values for regularization parameter\n",
        "\n",
        "# Perform GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model after hyperparameter tuning\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R-squared:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMy_HqsAoeaT",
        "outputId": "9583affb-a1d0-4d06-fc3e-c12bef9fc774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 499498.320842505\n",
            "R-squared: 0.30520568354384325\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "#idea two MLE guy from AZ\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize SelectKBest with f_regression for continuous target\n",
        "selector = SelectKBest(score_func=f_regression, k=100)  # select top 100 features\n",
        "\n",
        "# Fit selector to your data and transform both training and testing data\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)  # Use y_train here\n",
        "X_test_selected = selector.transform(X_test)  # Transform the test data as well\n",
        "\n",
        "# Train a regression model with filtered features\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_selected, y_train)  # Use y_train for training\n",
        "\n",
        "# Predict on the transformed test set\n",
        "y_pred = model.predict(X_test_selected)  # Use X_test_selected for prediction\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R-squared:\", r2_score(y_test, y_pred))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOscc0sKtZ0l",
        "outputId": "1ef6eb0b-8e8f-4bce-a76f-83a581d26b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 602518.8530926044\n",
            "R-squared: 0.16190574178442685\n"
          ]
        }
      ]
    }
  ]
}